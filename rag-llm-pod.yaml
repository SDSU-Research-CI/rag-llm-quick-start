apiVersion: v1
kind: Pod
metadata:
  name: rag-llm-ollama
  labels:
    k8s-app: rag-llm-ollama
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
            - key: nautilus.io/csu-tide
              operator: Exists
            - key: nvidia.com/gpu.product
              operator: In
              values:
              - NVIDIA-L40
  tolerations:
  - effect: NoSchedule
    key: nautilus.io/csu-tide
    operator: Exists
  containers:
  - name: rag-llm-ollama
    image: python
    command: ["sh", "-c", "echo 'Im a new pod' && sleep infinity"]
    resources:
      limits:
        nvidia.com/gpu: 1
        cpu: 2
        memory: 4Gi
      requests:
        nvidia.com/gpu: 1
        cpu: 2
        memory: 4Gi
    volumeMounts:
        - mountPath: /chroma
          name: rag-llm-chroma
  volumes:
  - name: rag-llm-chroma
    persistentVolumeClaim:
      claimName: rag-llm-chroma
